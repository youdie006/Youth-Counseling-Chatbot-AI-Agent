"""
ChromaDB ê¸°ë°˜ Vector Store - 0.3.21 ìµœì¢… í˜¸í™˜ ë²„ì „
"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
from loguru import logger
import os
import uuid
import time
import math
from datetime import datetime
import subprocess
import glob

from ..models.vector_models import SearchResult, DocumentInput, VectorStoreStats


class ChromaVectorStore:
    """ChromaDB ê¸°ë°˜ Vector Store - 0.3.21 ìµœì¢… í˜¸í™˜"""

    def __init__(self, collection_name: str = "teen_empathy_chat"):
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.embedding_model = None
        self.model_name = "jhgan/ko-sbert-multitask"
        self.cache_dir = "/app/cache"

    async def initialize(self):
        """ChromaDB ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” - ChromaDB íŒŒì¼ ì§ì ‘ ì‚¬ìš©"""
        try:
            logger.info("ChromaDB Vector Store ì´ˆê¸°í™” ì‹œì‘...")

            # ğŸ” í™˜ê²½ ê°ì§€
            is_huggingface = bool(os.getenv("SPACE_ID") or os.getenv("SPACE_AUTHOR_NAME"))
            is_local_dev = bool(os.getenv("LOCAL_DEV") or os.getenv("DEVELOPMENT_MODE"))

            logger.info(f"ğŸŒ í™˜ê²½ ê°ì§€ - HuggingFace: {is_huggingface}, Local: {is_local_dev}")

            # ğŸ¤— í—ˆê¹…í˜ì´ìŠ¤ í™˜ê²½ì—ì„œ ChromaDB ë‹¤ìš´ë¡œë“œ
            if is_huggingface:
                logger.info("ğŸ¤— í—ˆê¹…í˜ì´ìŠ¤ í™˜ê²½ - ChromaDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œë„")
                await self._download_chromadb_dataset()

            # ChromaDB ê²½ë¡œ ì„¤ì •
            db_path = os.getenv("CHROMADB_PATH", "/app/data/chromadb")
            os.makedirs(db_path, exist_ok=True)

            # ğŸ“‚ ChromaDB íŒŒì¼ ì¡´ì¬ í™•ì¸
            chroma_files = self._check_chromadb_files(db_path)
            logger.info(f"ğŸ“‚ ChromaDB íŒŒì¼ ìƒíƒœ: {chroma_files}")

            # ChromaDB 0.3.21 í˜¸í™˜ Settings
            settings = Settings(
                chroma_db_impl="duckdb+parquet",
                persist_directory=db_path,
                anonymized_telemetry=False
            )

            self.client = chromadb.Client(settings)

            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            logger.info(f"í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}")
            self.embedding_model = SentenceTransformer(
                self.model_name,
                cache_folder=self.cache_dir,
                device='cpu'
            )
            logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - ì°¨ì›: {self.embedding_model.get_sentence_embedding_dimension()}")

            # ğŸ” ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸
            try:
                existing_collections = self.client.list_collections()
                collection_names = [c.name for c in existing_collections]
                logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ë“¤: {collection_names}")

                # íƒ€ê²Ÿ ì»¬ë ‰ì…˜ ì°¾ê¸°
                target_collection = None
                possible_names = [self.collection_name, "teen_empathy_chat", "empathy_chat", "chat_data"]

                for name in possible_names:
                    if name in collection_names:
                        target_collection = name
                        break

                if target_collection:
                    self.collection = self.client.get_collection(name=target_collection)
                    existing_count = self.collection.count()
                    logger.info(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—°ê²°: {target_collection} ({existing_count}ê°œ ë¬¸ì„œ)")

                    if existing_count > 0:
                        logger.info("ğŸ‰ ê¸°ì¡´ ì„ë² ë”© ë°ì´í„° ì‚¬ìš© - ì´ˆê¸°í™” ì™„ë£Œ!")
                        return
                    else:
                        logger.warning("âš ï¸ ì»¬ë ‰ì…˜ì€ ìˆì§€ë§Œ ë¬¸ì„œê°€ ì—†ìŒ")

            except Exception as e:
                logger.warning(f"âš ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸ ì‹¤íŒ¨: {e}")

            # ğŸ”§ ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜ ë¹ˆ ê²½ìš° - ìƒˆë¡œ ìƒì„±
            logger.info("ğŸ”§ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ë° ê¸°ë³¸ ë°ì´í„° ì¶”ê°€")
            try:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={
                        "description": "Teen empathy conversation embeddings",
                        "created_at": datetime.now().isoformat(),
                        "environment": "huggingface" if is_huggingface else "local"
                    }
                )
                logger.info(f"ğŸ†• ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")

                # ê¸°ë³¸ ë°ì´í„° ì¶”ê°€
                await self._add_essential_data()

            except Exception as e:
                logger.error(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
                raise

            logger.info("âœ… ChromaDB Vector Store ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
            await self._fallback_initialize()

    async def _download_chromadb_dataset(self):
        """í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ChromaDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        try:
            logger.info("ğŸ“¥ ChromaDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")

            # ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ì¤€ë¹„
            download_dir = "/app/data"
            os.makedirs(download_dir, exist_ok=True)

            # huggingface-clië¥¼ ì‚¬ìš©í•´ì„œ ChromaDB íŒŒì¼ë“¤ ë‹¤ìš´ë¡œë“œ
            cmd = [
                "huggingface-cli", "download",
                "youdie006/simsimi-ai-agent-data",
                "--repo-type", "dataset",
                "--local-dir", download_dir,
                "--local-dir-use-symlinks", "False"
            ]

            logger.info(f"ğŸ“¥ ì‹¤í–‰ ëª…ë ¹: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
                cwd="/app"
            )

            if result.returncode == 0:
                logger.info("âœ… ChromaDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                logger.info(f"ğŸ“ ë‹¤ìš´ë¡œë“œ ë‚´ìš©: {result.stdout}")

                # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í™•ì¸
                downloaded_files = []
                for root, dirs, files in os.walk(download_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        downloaded_files.append(file_path)

                logger.info(f"ğŸ“‚ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë“¤: {downloaded_files}")

                # ChromaDB ê´€ë ¨ íŒŒì¼ í™•ì¸
                chromadb_files = [f for f in downloaded_files if any(ext in f.lower() for ext in ['.duckdb', '.parquet', 'chroma'])]
                logger.info(f"ğŸ—„ï¸ ChromaDB ê´€ë ¨ íŒŒì¼ë“¤: {chromadb_files}")

            else:
                logger.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
                logger.warning(f"ğŸ“¤ ì¶œë ¥: {result.stdout}")

        except subprocess.TimeoutExpired:
            logger.warning("âš ï¸ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼)")
        except Exception as e:
            logger.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _check_chromadb_files(self, db_path: str) -> dict:
        """ChromaDB íŒŒì¼ ì¡´ì¬ í™•ì¸"""
        try:
            files_info = {}

            # ì¼ë°˜ì ì¸ ChromaDB íŒŒì¼ íŒ¨í„´
            patterns = [
                "*.duckdb",
                "*.parquet",
                "chroma.sqlite3",
                "index/*",
                "*.bin"
            ]

            for pattern in patterns:
                files = glob.glob(os.path.join(db_path, "**", pattern), recursive=True)
                if files:
                    files_info[pattern] = files

            # ì „ì²´ íŒŒì¼ ëª©ë¡
            all_files = []
            if os.path.exists(db_path):
                for root, dirs, files in os.walk(db_path):
                    for file in files:
                        all_files.append(os.path.join(root, file))

            files_info["all_files"] = all_files
            files_info["total_count"] = len(all_files)

            return files_info

        except Exception as e:
            logger.warning(f"íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def _add_essential_data(self):
        """í•„ìˆ˜ ë°ì´í„° ì¶”ê°€ (ChromaDB íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)"""
        try:
            logger.info("ğŸ”§ í•„ìˆ˜ ë°ì´í„° ì¶”ê°€ ì¤‘...")

            essential_docs = [
                DocumentInput(
                    content="ì—„ë§ˆê°€ ê³„ì† ì”ì†Œë¦¬í•´ì„œ í™”ê°€ ë‚˜ìš”",
                    metadata={
                        "user_utterance": "ì—„ë§ˆê°€ ê³„ì† ì”ì†Œë¦¬í•´ì„œ í™”ê°€ ë‚˜ìš”",
                        "system_response": "ë¶€ëª¨ë‹˜ê³¼ì˜ ê°ˆë“±ì€ ì •ë§ í˜ë“¤ì§€. ì—„ë§ˆë„ ë„ˆë¥¼ ê±±ì •í•´ì„œ ê·¸ëŸ¬ëŠ” ê±´ ì•Œì§€ë§Œ, ì”ì†Œë¦¬ê°€ ê³„ì†ë˜ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ë°›ì„ ë§Œí•´.",
                        "emotion": "ë¶„ë…¸",
                        "relationship": "ë¶€ëª¨ë‹˜",
                        "data_source": "essential"
                    },
                    document_id="essential_parent_conflict"
                ),
                DocumentInput(
                    content="ì¹œêµ¬ê°€ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ì†ìƒí•´",
                    metadata={
                        "user_utterance": "ì¹œêµ¬ê°€ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ì†ìƒí•´",
                        "system_response": "ì¹œêµ¬ê°€ ë„ˆë¥¼ ë¬´ì‹œí•œë‹¤ê³  ëŠë¼ëŠ” êµ¬ì²´ì ì¸ ìƒí™©ì´ ìˆì—ˆë‚˜? ê·¸ëŸ° ê¸°ë¶„ì´ ë“¤ë©´ ì •ë§ ì†ìƒí•  ê²ƒ ê°™ì•„.",
                        "emotion": "ìƒì²˜",
                        "relationship": "ì¹œêµ¬",
                        "data_source": "essential"
                    },
                    document_id="essential_friend_hurt"
                ),
                DocumentInput(
                    content="ì‹œí—˜ì´ ê±±ì •ë¼ì„œ ì ì´ ì•ˆ ì™€ìš”",
                    metadata={
                        "user_utterance": "ì‹œí—˜ì´ ê±±ì •ë¼ì„œ ì ì´ ì•ˆ ì™€ìš”",
                        "system_response": "ì‹œí—˜ ìŠ¤íŠ¸ë ˆìŠ¤ëŠ” ì •ë§ í˜ë“¤ì–´. ë¶ˆì•ˆí•œ ë§ˆìŒì´ ë“œëŠ” ê±´ ë‹¹ì—°í•´. ê¹Šê²Œ ìˆ¨ì„ ì‰¬ê³  ì°¨ê·¼ì°¨ê·¼ ì¤€ë¹„í•´ë³´ì.",
                        "emotion": "ë¶ˆì•ˆ",
                        "relationship": "ê¸°íƒ€",
                        "data_source": "essential"
                    },
                    document_id="essential_exam_anxiety"
                ),
                DocumentInput(
                    content="ìš”ì¦˜ ìš°ìš¸í•´ì„œ ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´",
                    metadata={
                        "user_utterance": "ìš”ì¦˜ ìš°ìš¸í•´ì„œ ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´",
                        "system_response": "ìš°ìš¸í•œ ê¸°ë¶„ì´ ë“œëŠ” ê±´ ì •ë§ í˜ë“¤ì–´. í˜¼ì ê²¬ë””ì§€ ë§ê³  ì£¼ë³€ ì‚¬ëŒë“¤ê³¼ ì´ì•¼ê¸°í•´ë³´ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ì•„.",
                        "emotion": "ìŠ¬í””",
                        "relationship": "ê¸°íƒ€",
                        "data_source": "essential"
                    },
                    document_id="essential_depression"
                ),
                DocumentInput(
                    content="ì„ ìƒë‹˜ì´ ë‚˜ë§Œ ë¯¸ì›Œí•˜ëŠ” ê²ƒ ê°™ì•„",
                    metadata={
                        "user_utterance": "ì„ ìƒë‹˜ì´ ë‚˜ë§Œ ë¯¸ì›Œí•˜ëŠ” ê²ƒ ê°™ì•„",
                        "system_response": "ì„ ìƒë‹˜ì´ ë„ˆë¥¼ ë¯¸ì›Œí•œë‹¤ê³  ëŠë¼ëŠ” êµ¬ì²´ì ì¸ ìƒí™©ì´ ìˆì—ˆë‚˜? ì˜¤í•´ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆê¹Œ ì°¨ê·¼ì°¨ê·¼ ìƒê°í•´ë³´ì.",
                        "emotion": "ë‹¹í™©",
                        "relationship": "ì„ ìƒë‹˜",
                        "data_source": "essential"
                    },
                    document_id="essential_teacher_conflict"
                )
            ]

            await self.add_documents(essential_docs)
            logger.info(f"âœ… í•„ìˆ˜ ë°ì´í„° {len(essential_docs)}ê°œ ì¶”ê°€ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ í•„ìˆ˜ ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")

    async def _fallback_initialize(self):
        """í´ë°± ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ í´ë°± ì´ˆê¸°í™” ì‹œì‘...")

            self.client = chromadb.Client()

            if not self.embedding_model:
                self.embedding_model = SentenceTransformer(
                    self.model_name,
                    cache_folder=self.cache_dir,
                    device='cpu'
                )

            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                count = self.collection.count()
                logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—°ê²°: {self.collection_name} ({count}ê°œ)")

                if count == 0:
                    await self._add_essential_data()

            except Exception:
                self.collection = self.client.create_collection(name=self.collection_name)
                logger.info(f"ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")
                await self._add_essential_data()

            logger.info("âœ… í´ë°± ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ í´ë°± ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
            raise

    def create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """ì„ë² ë”© ìƒì„±"""
        if not self.embedding_model:
            raise ValueError("ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info(f"ì„ë² ë”© ìƒì„± ì¤‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")

        try:
            embeddings = self.embedding_model.encode(texts, convert_to_tensor=False)
            embeddings_list = embeddings.tolist()
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings_list)}ê°œ")
            return embeddings_list
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    async def add_documents(self, documents: List[DocumentInput]) -> List[str]:
        """ë¬¸ì„œë¥¼ Vector DBì— ì¶”ê°€"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info(f"ë¬¸ì„œ ì¶”ê°€ ì‹œì‘: {len(documents)}ê°œ")

        texts = [doc.content for doc in documents]
        metadatas = [doc.metadata or {} for doc in documents]
        document_ids = [doc.document_id or str(uuid.uuid4()) for doc in documents]

        # ë©”íƒ€ë°ì´í„°ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        for i, metadata in enumerate(metadatas):
            metadata.update({
                "timestamp": datetime.now().isoformat(),
                "content_length": len(texts[i]),
                "indexed_at": datetime.now().isoformat()
            })

        embeddings = self.create_embeddings(texts)

        # ë°°ì¹˜ ì²˜ë¦¬
        batch_size = 100
        for i in range(0, len(documents), batch_size):
            end_idx = min(i + batch_size, len(documents))

            self.collection.add(
                embeddings=embeddings[i:end_idx],
                documents=texts[i:end_idx],
                metadatas=metadatas[i:end_idx],
                ids=document_ids[i:end_idx]
            )

            logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì¶”ê°€ ì™„ë£Œ: {end_idx - i}ê°œ ë¬¸ì„œ")

        # 0.3.21ì—ì„œëŠ” persist() ëª…ì‹œì  í˜¸ì¶œ
        try:
            if hasattr(self.client, 'persist'):
                self.client.persist()
        except Exception as e:
            logger.warning(f"persist() í˜¸ì¶œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        logger.info(f"âœ… ë¬¸ì„œ {len(documents)}ê°œ ì¶”ê°€ ì™„ë£Œ")
        return document_ids

    def _calculate_similarity_from_distance(self, distance: float, method: str = "improved") -> float:
        """ê°œì„ ëœ ìœ ì‚¬ë„ ê³„ì‚°"""
        if method == "improved":
            return 1.0 / (1.0 + distance)
        elif method == "exponential":
            return math.exp(-distance)
        else:
            return 1.0 / (1.0 + distance)

    async def search(self, query: str, top_k: int = 5,
                    filter_metadata: Optional[Dict[str, Any]] = None,
                    similarity_method: str = "improved") -> List[SearchResult]:
        """ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ - ChromaDB 0.3.21 í˜¸í™˜"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        start_time = time.time()
        logger.info(f"ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: '{query[:50]}...', top_k: {top_k}")

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self.create_embeddings([query])[0]

        # ChromaDB 0.3.21 ê²€ìƒ‰ API
        search_kwargs = {
            "query_embeddings": [query_embedding],
            "n_results": top_k,
            "include": ["documents", "metadatas", "distances"]
        }

        # í•„í„°ë§ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        try:
            if filter_metadata:
                search_kwargs["where"] = filter_metadata
            results = self.collection.query(**search_kwargs)
        except Exception as e:
            logger.warning(f"í•„í„° ê²€ìƒ‰ ì‹¤íŒ¨, ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {e}")
            search_kwargs.pop("where", None)
            results = self.collection.query(**search_kwargs)

        # ê²°ê³¼ ì²˜ë¦¬
        search_results = []
        if results.get("documents") and results["documents"][0]:
            distances = results.get("distances", [[]])[0]
            documents = results["documents"][0]
            metadatas = results.get("metadatas", [[]])[0]
            ids = results.get("ids", [[]])[0]

            # í†µê³„ ë¡œê¹…
            if distances:
                min_dist = min(distances)
                max_dist = max(distances)
                avg_dist = sum(distances) / len(distances)
                logger.info(f"ğŸ“Š ê±°ë¦¬ í†µê³„ - ìµœì†Œ: {min_dist:.3f}, ìµœëŒ€: {max_dist:.3f}, í‰ê· : {avg_dist:.3f}")

            for i in range(len(documents)):
                distance = distances[i] if i < len(distances) else 1.0
                similarity_score = self._calculate_similarity_from_distance(distance, similarity_method)

                search_results.append(SearchResult(
                    content=documents[i],
                    metadata=metadatas[i] if i < len(metadatas) else {},
                    score=similarity_score,
                    document_id=ids[i] if i < len(ids) else f"result_{i}"
                ))

        search_time = (time.time() - start_time) * 1000
        logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼ ({search_time:.2f}ms)")

        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        search_results.sort(key=lambda x: x.score, reverse=True)

        # ìƒìœ„ ê²°ê³¼ ë¡œê¹…
        for i, result in enumerate(search_results[:3]):
            logger.info(f"ê²°ê³¼ {i+1}: ìœ ì‚¬ë„={result.score:.3f}, ë‚´ìš©='{result.content[:50]}...'")

        return search_results

    async def get_collection_stats(self) -> VectorStoreStats:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")

        try:
            count = self.collection.count()
            return VectorStoreStats(
                collection_name=self.collection_name,
                total_documents=count,
                embedding_model=self.model_name,
                embedding_dimension=self.embedding_model.get_sentence_embedding_dimension() if self.embedding_model else None,
                database_path=os.getenv("CHROMADB_PATH", "/app/data/chromadb"),
                status="healthy" if count >= 0 else "error",
                last_updated=datetime.now().isoformat()
            )
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    async def delete_documents(self, document_ids: List[str]) -> bool:
        """ë¬¸ì„œ ì‚­ì œ"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            self.collection.delete(ids=document_ids)

            try:
                if hasattr(self.client, 'persist'):
                    self.client.persist()
            except Exception as e:
                logger.warning(f"persist() ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

            logger.info(f"{len(document_ids)}ê°œ ì‚­ì œ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    async def clear_collection(self) -> bool:
        """ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            self.client.delete_collection(name=self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={
                    "description": "Teen empathy conversation embeddings",
                    "created_at": datetime.now().isoformat()
                }
            )
            logger.info(f"âœ… ì»¬ë ‰ì…˜ {self.collection_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_vector_store_instance = None

async def get_vector_store() -> ChromaVectorStore:
    """Vector Store ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _vector_store_instance
    if _vector_store_instance is None:
        collection_name = os.getenv("COLLECTION_NAME", "teen_empathy_chat")
        _vector_store_instance = ChromaVectorStore(collection_name)
        await _vector_store_instance.initialize()
    return _vector_store_instance

def reset_vector_store():
    """Vector Store ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸ìš©)"""
    global _vector_store_instance
    _vector_store_instance = None