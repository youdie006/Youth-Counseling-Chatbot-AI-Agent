"""
ChromaDB ê¸°ë°˜ Vector Store - 0.3.21 í˜¸í™˜ ë²„ì „
"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
from loguru import logger
import os
import uuid
import time
from datetime import datetime

from ..models.vector_models import SearchResult, DocumentInput, VectorStoreStats


class ChromaVectorStore:
    """ChromaDB ê¸°ë°˜ Vector Store - 0.3.21 í˜¸í™˜"""

    def __init__(self, collection_name: str = "teen_empathy_chat"):
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.embedding_model = None
        self.model_name = "jhgan/ko-sbert-multitask"
        self.cache_dir = "/app/cache"

    async def initialize(self):
        """ChromaDB ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ChromaDB Vector Store ì´ˆê¸°í™” ì‹œì‘...")

            db_path = os.getenv("CHROMADB_PATH", "/app/data/chromadb")
            os.makedirs(db_path, exist_ok=True)

            # ChromaDB 0.3.21 ì„¤ì •
            self.client = chromadb.PersistentClient(
                path=db_path,
                settings=Settings(
                    allow_reset=True,
                    anonymized_telemetry=False
                )
            )

            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            logger.info(f"í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}")
            self.embedding_model = SentenceTransformer(
                self.model_name,
                cache_folder=self.cache_dir,
                device='cpu'
            )
            logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - ì°¨ì›: {self.embedding_model.get_sentence_embedding_dimension()}")

            # ì»¬ë ‰ì…˜ ìƒì„±/ì—°ê²° (0.3.21 ë°©ì‹)
            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—°ê²°: {self.collection_name}")
            except ValueError:
                # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={
                        "description": "Teen empathy conversation embeddings",
                        "created_at": datetime.now().isoformat()
                    }
                )
                logger.info(f"ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")

            logger.info("âœ… ChromaDB Vector Store ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """ì„ë² ë”© ìƒì„±"""
        if not self.embedding_model:
            raise ValueError("ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info(f"ì„ë² ë”© ìƒì„± ì¤‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")

        try:
            embeddings = self.embedding_model.encode(texts, convert_to_tensor=False)
            embeddings_list = embeddings.tolist()
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings_list)}ê°œ")
            return embeddings_list
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    async def add_documents(self, documents: List[DocumentInput]) -> List[str]:
        """ë¬¸ì„œë¥¼ Vector DBì— ì¶”ê°€"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info(f"ë¬¸ì„œ ì¶”ê°€ ì‹œì‘: {len(documents)}ê°œ")

        texts = [doc.content for doc in documents]
        metadatas = [doc.metadata or {} for doc in documents]
        document_ids = [doc.document_id or str(uuid.uuid4()) for doc in documents]

        # ë©”íƒ€ë°ì´í„°ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        for metadata in metadatas:
            metadata.update({
                "timestamp": datetime.now().isoformat(),
                "content_length": len(texts[metadatas.index(metadata)]),
                "indexed_at": datetime.now().isoformat()
            })

        embeddings = self.create_embeddings(texts)

        # ë°°ì¹˜ ì²˜ë¦¬
        batch_size = 100
        for i in range(0, len(documents), batch_size):
            end_idx = min(i + batch_size, len(documents))

            self.collection.add(
                embeddings=embeddings[i:end_idx],
                documents=texts[i:end_idx],
                metadatas=metadatas[i:end_idx],
                ids=document_ids[i:end_idx]
            )

            logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì¶”ê°€ ì™„ë£Œ: {end_idx - i}ê°œ ë¬¸ì„œ")

        logger.info(f"âœ… ë¬¸ì„œ {len(documents)}ê°œ ì¶”ê°€ ì™„ë£Œ")
        return document_ids

    async def search(self, query: str, top_k: int = 5,
                    filter_metadata: Optional[Dict[str, Any]] = None) -> List[SearchResult]:
        """ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        start_time = time.time()
        logger.info(f"ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: '{query[:50]}...', top_k: {top_k}")

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        logger.info("ì„ë² ë”© ìƒì„± ì¤‘: 1ê°œ í…ìŠ¤íŠ¸")
        query_embedding = self.create_embeddings([query])[0]
        logger.info("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: 1ê°œ")

        # ê²€ìƒ‰ ìˆ˜í–‰ (ChromaDB 0.3.21 API)
        search_kwargs = {
            "query_embeddings": [query_embedding],
            "n_results": top_k,
            "include": ["documents", "metadatas", "distances"]
        }

        if filter_metadata:
            search_kwargs["where"] = filter_metadata

        results = self.collection.query(**search_kwargs)

        # ğŸ”§ ìœ ì‚¬ë„ ê³„ì‚° (L2 ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜)
        search_results = []
        if results["documents"] and results["documents"][0]:
            for i in range(len(results["documents"][0])):
                distance = results["distances"][0][i]

                # L2 ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                if distance <= 0:
                    similarity_score = 1.0
                elif distance >= 2.0:
                    similarity_score = 0.0
                else:
                    similarity_score = max(0.0, 1.0 - (distance / 2.0))

                search_results.append(SearchResult(
                    content=results["documents"][0][i],
                    metadata=results["metadatas"][0][i] or {},
                    score=similarity_score,
                    document_id=results["ids"][0][i] if results.get("ids") else f"result_{i}"
                ))

        search_time = (time.time() - start_time) * 1000
        logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼ ({search_time:.2f}ms)")

        # ğŸ” ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        for i, result in enumerate(search_results):
            logger.info(f"ê²°ê³¼ {i+1}: ìœ ì‚¬ë„={result.score:.3f}, ë‚´ìš©='{result.content[:50]}...'")

        return search_results

    async def get_collection_stats(self) -> VectorStoreStats:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")

        try:
            count = self.collection.count()
            return VectorStoreStats(
                collection_name=self.collection_name,
                total_documents=count,
                embedding_model=self.model_name,
                embedding_dimension=self.embedding_model.get_sentence_embedding_dimension() if self.embedding_model else None,
                database_path=os.getenv("CHROMADB_PATH", "/app/data/chromadb"),
                status="healthy" if count >= 0 else "error",
                last_updated=datetime.now().isoformat()
            )
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    async def delete_documents(self, document_ids: List[str]) -> bool:
        """ë¬¸ì„œ ì‚­ì œ"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            self.collection.delete(ids=document_ids)
            logger.info(f"{len(document_ids)}ê°œ ì‚­ì œ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    async def update_document(self, document_id: str, document: DocumentInput) -> bool:
        """ë¬¸ì„œ ì—…ë°ì´íŠ¸"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ
            await self.delete_documents([document_id])

            # ìƒˆ ë¬¸ì„œ ì¶”ê°€
            document.document_id = document_id
            await self.add_documents([document])

            logger.info(f"{document_id} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    async def clear_collection(self) -> bool:
        """ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ì»¬ë ‰ì…˜ ì‚­ì œ
            self.client.delete_collection(name=self.collection_name)

            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={
                    "description": "Teen empathy conversation embeddings",
                    "created_at": datetime.now().isoformat()
                }
            )

            logger.info(f"âœ… ì»¬ë ‰ì…˜ {self.collection_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_vector_store_instance = None

async def get_vector_store() -> ChromaVectorStore:
    """Vector Store ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _vector_store_instance
    if _vector_store_instance is None:
        collection_name = os.getenv("COLLECTION_NAME", "teen_empathy_chat")
        _vector_store_instance = ChromaVectorStore(collection_name)
        await _vector_store_instance.initialize()
    return _vector_store_instance

def reset_vector_store():
    """Vector Store ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸ìš©)"""
    global _vector_store_instance
    _vector_store_instance = None