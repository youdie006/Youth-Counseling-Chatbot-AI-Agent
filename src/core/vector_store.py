"""
ChromaDB ê¸°ë°˜ Vector Store - 0.3.21 ìµœì¢… í˜¸í™˜ ë²„ì „
"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
from loguru import logger
import os
import uuid
import time
import math
from datetime import datetime

from ..models.vector_models import SearchResult, DocumentInput, VectorStoreStats


class ChromaVectorStore:
    """ChromaDB ê¸°ë°˜ Vector Store - 0.3.21 ìµœì¢… í˜¸í™˜"""

    def __init__(self, collection_name: str = "teen_empathy_chat"):
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.embedding_model = None
        self.model_name = "jhgan/ko-sbert-multitask"
        self.cache_dir = "/app/cache"

    async def initialize(self):
        """ChromaDB ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” - 0.3.21 ìµœì¢… í˜¸í™˜"""
        try:
            logger.info("ChromaDB Vector Store ì´ˆê¸°í™” ì‹œì‘...")

            db_path = os.getenv("CHROMADB_PATH", "/app/data/chromadb")
            os.makedirs(db_path, exist_ok=True)

            # ğŸ”§ ChromaDB 0.3.21 í˜¸í™˜ Settings (allow_reset ì œê±°!)
            settings = Settings(
                chroma_db_impl="duckdb+parquet",
                persist_directory=db_path,
                anonymized_telemetry=False
            )

            # 0.3.21ì—ì„œëŠ” Client() ì‚¬ìš©
            self.client = chromadb.Client(settings)

            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            logger.info(f"í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}")
            self.embedding_model = SentenceTransformer(
                self.model_name,
                cache_folder=self.cache_dir,
                device='cpu'
            )
            logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - ì°¨ì›: {self.embedding_model.get_sentence_embedding_dimension()}")

            # ì»¬ë ‰ì…˜ ìƒì„±/ì—°ê²° (0.3.21 ë°©ì‹)
            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—°ê²°: {self.collection_name}")
            except Exception:
                # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={
                        "description": "Teen empathy conversation embeddings",
                        "created_at": datetime.now().isoformat()
                    }
                )
                logger.info(f"ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")

            logger.info("âœ… ChromaDB Vector Store ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ë” ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
            try:
                logger.info("ğŸ”„ ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
                self.client = chromadb.Client()

                # ì„ë² ë”© ëª¨ë¸ì€ ì´ë¯¸ ì‹œë„í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µí•˜ì§€ ì•ŠìŒ
                if not self.embedding_model:
                    logger.info(f"í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}")
                    self.embedding_model = SentenceTransformer(
                        self.model_name,
                        cache_folder=self.cache_dir,
                        device='cpu'
                    )

                # ì»¬ë ‰ì…˜ ìƒì„±/ì—°ê²°
                try:
                    self.collection = self.client.get_collection(name=self.collection_name)
                    logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—°ê²°: {self.collection_name}")
                except Exception:
                    self.collection = self.client.create_collection(name=self.collection_name)
                    logger.info(f"ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")

                logger.info("âœ… ChromaDB Vector Store ì´ˆê¸°í™” ì™„ë£Œ (ê°„ë‹¨í•œ ë°©ì‹)")

            except Exception as e2:
                logger.error(f"âŒ ê°„ë‹¨í•œ ë°©ì‹ë„ ì‹¤íŒ¨: {e2}")
                raise

    def create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """ì„ë² ë”© ìƒì„±"""
        if not self.embedding_model:
            raise ValueError("ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info(f"ì„ë² ë”© ìƒì„± ì¤‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")

        try:
            embeddings = self.embedding_model.encode(texts, convert_to_tensor=False)
            embeddings_list = embeddings.tolist()
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings_list)}ê°œ")
            return embeddings_list
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    async def add_documents(self, documents: List[DocumentInput]) -> List[str]:
        """ë¬¸ì„œë¥¼ Vector DBì— ì¶”ê°€"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info(f"ë¬¸ì„œ ì¶”ê°€ ì‹œì‘: {len(documents)}ê°œ")

        texts = [doc.content for doc in documents]
        metadatas = [doc.metadata or {} for doc in documents]
        document_ids = [doc.document_id or str(uuid.uuid4()) for doc in documents]

        # ë©”íƒ€ë°ì´í„°ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        for metadata in metadatas:
            metadata.update({
                "timestamp": datetime.now().isoformat(),
                "content_length": len(texts[metadatas.index(metadata)]),
                "indexed_at": datetime.now().isoformat()
            })

        embeddings = self.create_embeddings(texts)

        # ë°°ì¹˜ ì²˜ë¦¬
        batch_size = 100
        for i in range(0, len(documents), batch_size):
            end_idx = min(i + batch_size, len(documents))

            self.collection.add(
                embeddings=embeddings[i:end_idx],
                documents=texts[i:end_idx],
                metadatas=metadatas[i:end_idx],
                ids=document_ids[i:end_idx]
            )

            logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì¶”ê°€ ì™„ë£Œ: {end_idx - i}ê°œ ë¬¸ì„œ")

        # 0.3.21ì—ì„œëŠ” persist() ëª…ì‹œì  í˜¸ì¶œ
        try:
            if hasattr(self.client, 'persist'):
                self.client.persist()
        except Exception as e:
            logger.warning(f"persist() í˜¸ì¶œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        logger.info(f"âœ… ë¬¸ì„œ {len(documents)}ê°œ ì¶”ê°€ ì™„ë£Œ")
        return document_ids

    def _calculate_similarity_from_distance(self, distance: float, method: str = "improved") -> float:
        """ê°œì„ ëœ ìœ ì‚¬ë„ ê³„ì‚°"""
        if method == "improved":
            return 1.0 / (1.0 + distance)
        elif method == "exponential":
            return math.exp(-distance)
        else:
            return 1.0 / (1.0 + distance)

    async def search(self, query: str, top_k: int = 5,
                    filter_metadata: Optional[Dict[str, Any]] = None,
                    similarity_method: str = "improved") -> List[SearchResult]:
        """ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ - ChromaDB 0.3.21 í˜¸í™˜"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        start_time = time.time()
        logger.info(f"ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: '{query[:50]}...', top_k: {top_k}")

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self.create_embeddings([query])[0]

        # ChromaDB 0.3.21 ê²€ìƒ‰ API
        search_kwargs = {
            "query_embeddings": [query_embedding],
            "n_results": top_k,
            "include": ["documents", "metadatas", "distances"]
        }

        # í•„í„°ë§ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        try:
            if filter_metadata:
                search_kwargs["where"] = filter_metadata
            results = self.collection.query(**search_kwargs)
        except Exception as e:
            logger.warning(f"í•„í„° ê²€ìƒ‰ ì‹¤íŒ¨, ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {e}")
            search_kwargs.pop("where", None)
            results = self.collection.query(**search_kwargs)

        # ê²°ê³¼ ì²˜ë¦¬
        search_results = []
        if results.get("documents") and results["documents"][0]:
            distances = results.get("distances", [[]])[0]
            documents = results["documents"][0]
            metadatas = results.get("metadatas", [[]])[0]
            ids = results.get("ids", [[]])[0]

            # í†µê³„ ë¡œê¹…
            if distances:
                min_dist = min(distances)
                max_dist = max(distances)
                avg_dist = sum(distances) / len(distances)
                logger.info(f"ğŸ“Š ê±°ë¦¬ í†µê³„ - ìµœì†Œ: {min_dist:.3f}, ìµœëŒ€: {max_dist:.3f}, í‰ê· : {avg_dist:.3f}")

            for i in range(len(documents)):
                distance = distances[i] if i < len(distances) else 1.0
                similarity_score = self._calculate_similarity_from_distance(distance, similarity_method)

                search_results.append(SearchResult(
                    content=documents[i],
                    metadata=metadatas[i] if i < len(metadatas) else {},
                    score=similarity_score,
                    document_id=ids[i] if i < len(ids) else f"result_{i}"
                ))

        search_time = (time.time() - start_time) * 1000
        logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼ ({search_time:.2f}ms)")

        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        search_results.sort(key=lambda x: x.score, reverse=True)

        # ìƒìœ„ ê²°ê³¼ ë¡œê¹…
        for i, result in enumerate(search_results[:3]):
            logger.info(f"ê²°ê³¼ {i+1}: ìœ ì‚¬ë„={result.score:.3f}, ë‚´ìš©='{result.content[:50]}...'")

        return search_results

    async def get_collection_stats(self) -> VectorStoreStats:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")

        try:
            count = self.collection.count()
            return VectorStoreStats(
                collection_name=self.collection_name,
                total_documents=count,
                embedding_model=self.model_name,
                embedding_dimension=self.embedding_model.get_sentence_embedding_dimension() if self.embedding_model else None,
                database_path=os.getenv("CHROMADB_PATH", "/app/data/chromadb"),
                status="healthy" if count >= 0 else "error",
                last_updated=datetime.now().isoformat()
            )
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    async def delete_documents(self, document_ids: List[str]) -> bool:
        """ë¬¸ì„œ ì‚­ì œ"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            self.collection.delete(ids=document_ids)

            try:
                if hasattr(self.client, 'persist'):
                    self.client.persist()
            except Exception as e:
                logger.warning(f"persist() ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

            logger.info(f"{len(document_ids)}ê°œ ì‚­ì œ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    async def clear_collection(self) -> bool:
        """ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ"""
        if not self.collection:
            raise ValueError("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            self.client.delete_collection(name=self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={
                    "description": "Teen empathy conversation embeddings",
                    "created_at": datetime.now().isoformat()
                }
            )
            logger.info(f"âœ… ì»¬ë ‰ì…˜ {self.collection_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_vector_store_instance = None

async def get_vector_store() -> ChromaVectorStore:
    """Vector Store ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _vector_store_instance
    if _vector_store_instance is None:
        collection_name = os.getenv("COLLECTION_NAME", "teen_empathy_chat")
        _vector_store_instance = ChromaVectorStore(collection_name)
        await _vector_store_instance.initialize()
    return _vector_store_instance

def reset_vector_store():
    """Vector Store ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸ìš©)"""
    global _vector_store_instance
    _vector_store_instance = None